{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import sys, math, os\n",
    "from os.path import isfile, join\n",
    "from os import walk, listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#繁簡轉換\n",
    "from langconv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加載 jieba 用戶字典、停用詞\n",
    "jieba.load_userdict('userdict.txt')\n",
    "jieba.analyse.set_stop_words('Chinese_stop.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 stopwords 表\n",
    "with open('Chinese_stop.txt', 'r', encoding = 'utf-8') as f:\n",
    "    stopwords = []\n",
    "    for word in f:\n",
    "            # 換行符號只算一個字元\n",
    "            stopwords.append(word[:-1])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stories\n",
    "def loadstories():\n",
    "    stories_in_folder = [f for f in listdir('stories/') if isfile(join('stories/',f))]\n",
    "\n",
    "    words_in_each_stories = []\n",
    "\n",
    "    for story in stories_in_folder:\n",
    "        with open('stories/' + story, 'r',encoding='utf-8', errors='replace') as f:\n",
    "            story_temp = f.read()\n",
    "        f.close()\n",
    "\n",
    "        story_temp = Converter('zh-hant').convert(story_temp)\n",
    "        story_words = jieba.cut(story_temp,cut_all = True)\n",
    "        word_list = ''\n",
    "        for word in story_words:\n",
    "            if \"\\n\" in word or word in stopwords:\n",
    "                continue\n",
    "            else:\n",
    "                word_list += word\n",
    "                word_list += \" \"\n",
    "#             print(word_list)\n",
    "        words_in_each_stories.append(word_list)\n",
    "    return stories_in_folder, words_in_each_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl , v = loadstories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = v\n",
    "# corpus = [storywords0,storywords1,storywords2]\n",
    "\n",
    "#該類會將文本中的詞語轉換為詞頻矩陣，矩陣元素a[i][j] 表示j詞在i類文本下的詞頻\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#該類會統計每個詞語的tf-idf權值\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "#第一個fit_transform是計算tf-idf，第二個fit_transform是將文本轉為詞頻矩陣\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "#獲取詞袋模型中的所有詞語\n",
    "word = vectorizer.get_feature_names()\n",
    "\n",
    "#將tf-idf矩陣抽取出來，元素a[i][j]表示j詞在i類文本中的tf-idf權重\n",
    "weight = tfidf.toarray()\n",
    "\n",
    "#打印每類文本的tf-idf詞語權重，第一個for遍歷所有文本，第二個for便利某一類文本下的詞語權重\n",
    "# for i in range(len(weight)):\n",
    "#     print(u\"-------這裡輸出第\",i,u\"類文本的詞語tf-idf權重------\")\n",
    "#     for j in range(len(word)):\n",
    "#         #找出特定相關性以上的詞語\n",
    "#         if weight[i][j] > 0.05 :\n",
    "#             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['海外 工作 ']\n"
     ]
    }
   ],
   "source": [
    "# user 的搜尋語句\n",
    "q = '海外工作'\n",
    "q_words_cut = jieba.cut(q,cut_all='True')\n",
    "q_words_string = ''\n",
    "for word in q_words_cut:\n",
    "    q_words_string += word\n",
    "    q_words_string += ' '\n",
    "    \n",
    "q_words = [q_words_string]\n",
    "print(q_words)\n",
    "\n",
    "q_tfidf = vectorizer.transform(q_words).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 0.20263269309604187, 32: 0.4686601088766346, 76: 0.19156752159381576, 96: 0.25446930961758907, 109: 0.14814495802415611}\n",
      "7 0.20263269309604187 ux工作上練習用戶訪談的小技巧.txt\n",
      "32 0.4686601088766346 ux-ui設計師海外面試心得記錄.txt\n",
      "76 0.19156752159381576 在國外工作有感.txt\n",
      "96 0.25446930961758907 ui-ux設計師的接案二三事-上.txt\n",
      "109 0.14814495802415611 we-need-you-aapd-第二屆團隊夥伴招募.txt\n"
     ]
    }
   ],
   "source": [
    "highests = {'a':0}\n",
    "\n",
    "for index, vector in enumerate(weight):    \n",
    "    vs = cosine_similarity([q_tfidf[0],vector])\n",
    "    sim = vs[0,1]\n",
    "    min_in_highests_key = min(highests,key = highests.get)\n",
    "    min_in_highests = highests[min_in_highests_key]\n",
    "#     print(min_in_highests_key,min_in_highests)\n",
    "    if sim > min_in_highests:\n",
    "        highests[index] = sim\n",
    "        if len(highests) > 5:\n",
    "            highests.pop(min_in_highests_key)\n",
    "    else:\n",
    "        continue\n",
    "print(highests)\n",
    "for h in highests:\n",
    "    highests[h] = np.float64(highests[h]).item()\n",
    "    print(h, highests[h], sl[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ui-ux設計師的接案二三事-上.txt'"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl[96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3203091044387575"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float64(highests[7]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6483"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={\"a\":1,\"b\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n"
     ]
    }
   ],
   "source": [
    "for i in d:\n",
    "    print(i,d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(d,key=d.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把文章詞表存到 storywordsi 的變數中\n",
    "```\n",
    "for i in range(3):\n",
    "    filename = 'story'+ str(i+1) +'.txt'\n",
    "    f = open(filename,'r')\n",
    "    story = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    story = Converter('zh-hant').convert(story)\n",
    "    \n",
    "    wordlist = jieba.cut(story,cut_all = True)\n",
    "    locals()['storywords' + str(i)] = ''\n",
    "    for word in wordlist:\n",
    "        if \"\\n\" in word or word in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            locals()['storywords' + str(i)] += word\n",
    "            locals()['storywords' + str(i)] += \" \"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
