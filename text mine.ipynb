{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import sys, math, os, json\n",
    "from os.path import isfile, join\n",
    "from os import walk, listdir\n",
    "import numpy as np\n",
    "\n",
    "#繁簡轉換\n",
    "from langconv import *\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/hs/lfrgdf0j4fv056xs2p3y5_r40000gn/T/jieba.cache\n",
      "Loading model cost 0.771 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 加載 jieba 用戶字典、停用詞\n",
    "jieba.load_userdict('userdict.txt')\n",
    "jieba.analyse.set_stop_words('Chinese_stop.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 stopwords 表\n",
    "with open('Chinese_stop.txt', 'r', encoding = 'utf-8') as f:\n",
    "    chinese_stop = []\n",
    "    for word in f:\n",
    "            # 換行符號只算一個字元\n",
    "            chinese_stop.append(word[:-1])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stories\n",
    "def loadstories():\n",
    "    stories_in_folder = [f for f in listdir('stories/') if isfile(join('stories/',f))]\n",
    "\n",
    "    words_in_each_stories = []\n",
    "\n",
    "    for story in stories_in_folder:\n",
    "        with open('stories/' + story, 'r',encoding='utf-8', errors='replace') as f:\n",
    "            story_temp = f.read()\n",
    "        f.close()\n",
    "\n",
    "        story_temp = Converter('zh-hant').convert(story_temp)\n",
    "        story_words = jieba.cut(story_temp,cut_all = True)\n",
    "        word_list = ''\n",
    "        for word in story_words:\n",
    "            if word in chinese_stop or word.lower() in english_stop:\n",
    "                continue\n",
    "            else:\n",
    "                word_list += word\n",
    "                word_list += \" \"\n",
    "#             print(word_list)\n",
    "        words_in_each_stories.append(word_list)\n",
    "    return stories_in_folder, words_in_each_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getweight(v,q):\n",
    "    corpus = v\n",
    "    # corpus = [storywords0,storywords1,storywords2]\n",
    "\n",
    "    #該類會將文本中的詞語轉換為詞頻矩陣，矩陣元素a[i][j] 表示j詞在i類文本下的詞頻\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    #該類會統計每個詞語的tf-idf權值\n",
    "    transformer = TfidfTransformer()\n",
    "\n",
    "    #第一個fit_transform是計算tf-idf，第二個fit_transform是將文本轉為詞頻矩陣\n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "    #獲取詞袋模型中的所有詞語\n",
    "    word = vectorizer.get_feature_names()\n",
    "\n",
    "    #將tf-idf矩陣抽取出來，元素a[i][j]表示j詞在i類文本中的tf-idf權重\n",
    "    all_w = tfidf.toarray()\n",
    "\n",
    "    \n",
    "    #########\n",
    "    q_words_cut = jieba.cut(q,cut_all='True')\n",
    "    q_words_string = ''\n",
    "    for w in q_words_cut:\n",
    "        q_words_string += w\n",
    "        q_words_string += ' '\n",
    "\n",
    "    q_words = [q_words_string]\n",
    "    # print(q_words)\n",
    "\n",
    "    q_w = vectorizer.transform(q_words).toarray()\n",
    "    \n",
    "    \n",
    "    return all_w, q_w\n",
    "\n",
    "\n",
    "    #打印每類文本的tf-idf詞語權重，第一個for遍歷所有文本，第二個for便利某一類文本下的詞語權重\n",
    "    # for i in range(len(weight)):\n",
    "    #     print(u\"-------這裡輸出第\",i,u\"類文本的詞語tf-idf權重------\")\n",
    "    #     for j in range(len(word)):\n",
    "    #         #找出特定相關性以上的詞語\n",
    "    #         if weight[i][j] > 0.05 :\n",
    "    #             print(word[j],weight[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user 的搜尋語句\n",
    "def userquery(q):\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    q_words_cut = jieba.cut(q,cut_all='True')\n",
    "    q_words_string = ''\n",
    "    for word in q_words_cut:\n",
    "        q_words_string += word\n",
    "        q_words_string += ' '\n",
    "\n",
    "    q_words = [q_words_string]\n",
    "    print(q_words)\n",
    "\n",
    "    q_tfidf = vectorizer.transform(q_words).toarray()\n",
    "    return q_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStories(weight_all, q_tfidf, storylist):\n",
    "\n",
    "    highests = {'a':0}\n",
    "    \n",
    "    for index, vector in enumerate(weight_all):    \n",
    "        vs = cosine_similarity([q_tfidf[0],vector])\n",
    "        sim = vs[0,1]\n",
    "        min_in_highests_key = min(highests,key = highests.get)\n",
    "        min_in_highests = highests[min_in_highests_key]\n",
    "        # print(min_in_highests_key,min_in_highests)\n",
    "        if sim > min_in_highests:\n",
    "            highests[index] = sim\n",
    "            if len(highests) > 5:\n",
    "                highests.pop(min_in_highests_key)\n",
    "        else:\n",
    "            continue\n",
    "    # print(highests)\n",
    "    for h in highests:\n",
    "        highests[h] = np.float64(highests[h]).item()\n",
    "        \n",
    "    result = []\n",
    "    for h in highests:\n",
    "        highests[h] = np.float64(highests[h]).item()\n",
    "        tmp = { 'number': h,\n",
    "                'title': storylist[h][:-4],\n",
    "                'score': highests[h]\n",
    "                }\n",
    "        result.append(tmp)\n",
    "        # print(h, highests[h], storylist[h])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl , w = loadstories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '今天要吃什麼，想要學一點東西'\n",
    "# weight_q = userquery(q)\n",
    "weight_all,q_tfidf = getweight(w,q)\n",
    "h = getStories(weight_all, q_tfidf, sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in h:\n",
    "    for s in l['stories']:\n",
    "        if rec['title'] == s['slug']:\n",
    "            rec['url'] = s['url']\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'number': 75,\n",
       "  'title': '新手設計師成長日記-配色',\n",
       "  'score': 0.0786686164749629,\n",
       "  'url': 'http://medium.com/p/aaa2e6d149b5'},\n",
       " {'number': 127,\n",
       "  'title': 'ui設計筆記工具篇-flow-神器-動態做好code-就完成',\n",
       "  'score': 0.08556185657471671,\n",
       "  'url': 'http://medium.com/p/5d4e456a8b8f'},\n",
       " {'number': 134,\n",
       "  'title': '新手上路-ui設計師的求職問答集',\n",
       "  'score': 0.08163062535461371,\n",
       "  'url': 'http://medium.com/p/c767b8471064'},\n",
       " {'number': 139,\n",
       "  'title': '在-sketch-中運用-iconfont',\n",
       "  'score': 0.13313415067687795,\n",
       "  'url': 'http://medium.com/p/4fae5b023bd'},\n",
       " {'number': 159,\n",
       "  'title': '所以-你想學ux-上-ux的起源',\n",
       "  'score': 0.07737379709287504,\n",
       "  'url': 'http://medium.com/p/c637f33f86a4'}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createdAt': 1533626576651,\n",
       " 'internalReferrerViews': 0,\n",
       " 'creatorId': 'ca09b47c1f3e',\n",
       " 'title': '使用者與產品的初次約會（上篇） — 理論與心法',\n",
       " 'createdAtTime': '2018-08-07 15:22:57',\n",
       " 'dataUpdateAt': '2018-08-09 11:45:18',\n",
       " 'readingTime': 1.5198113207547168,\n",
       " 'slug': '使用者與產品的初次約會-上篇-理論與心法',\n",
       " 'firstPublishedAtBucket': 'August 2018',\n",
       " 'creatorUrl': 'http://medium.com/u/ca09b47c1f3e',\n",
       " 'claps': 1108,\n",
       " 'tags': ['設計', '設計思考', 'ux', '产品设计', '成長駭客'],\n",
       " 'postId': 'ba932933d048',\n",
       " 'views': 830,\n",
       " 'firstPublishedAtTime': '2018-08-07 15:58:50',\n",
       " 'latestPublishedAtTime': '2018-08-08 01:54:08',\n",
       " 'reads': 321,\n",
       " 'upvotes': 89,\n",
       " 'firstPublishedAt': 1533628729900,\n",
       " 'url': 'http://medium.com/p/ba932933d048',\n",
       " 'friendsLinkViews': 0,\n",
       " 'collectionId': '1e6cb3374f6'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l['stories'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2018-08-09_stories_list.json','r') as f:\n",
    "    l = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createdAt': 1533626576651,\n",
       " 'internalReferrerViews': 0,\n",
       " 'creatorId': 'ca09b47c1f3e',\n",
       " 'title': '使用者與產品的初次約會（上篇） — 理論與心法',\n",
       " 'createdAtTime': '2018-08-07 15:22:57',\n",
       " 'dataUpdateAt': '2018-08-09 11:45:18',\n",
       " 'readingTime': 1.5198113207547168,\n",
       " 'slug': '使用者與產品的初次約會-上篇-理論與心法',\n",
       " 'firstPublishedAtBucket': 'August 2018',\n",
       " 'creatorUrl': 'http://medium.com/u/ca09b47c1f3e',\n",
       " 'claps': 1108,\n",
       " 'tags': ['設計', '設計思考', 'ux', '产品设计', '成長駭客'],\n",
       " 'postId': 'ba932933d048',\n",
       " 'views': 830,\n",
       " 'firstPublishedAtTime': '2018-08-07 15:58:50',\n",
       " 'latestPublishedAtTime': '2018-08-08 01:54:08',\n",
       " 'reads': 321,\n",
       " 'upvotes': 89,\n",
       " 'firstPublishedAt': 1533628729900,\n",
       " 'url': 'http://medium.com/p/ba932933d048',\n",
       " 'friendsLinkViews': 0,\n",
       " 'collectionId': '1e6cb3374f6'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l['stories'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把文章詞表存到 storywordsi 的變數中\n",
    "```\n",
    "for i in range(3):\n",
    "    filename = 'story'+ str(i+1) +'.txt'\n",
    "    f = open(filename,'r')\n",
    "    story = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    story = Converter('zh-hant').convert(story)\n",
    "    \n",
    "    wordlist = jieba.cut(story,cut_all = True)\n",
    "    locals()['storywords' + str(i)] = ''\n",
    "    for word in wordlist:\n",
    "        if \"\\n\" in word or word in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            locals()['storywords' + str(i)] += word\n",
    "            locals()['storywords' + str(i)] += \" \"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
